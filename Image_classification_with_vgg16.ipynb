{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vgg16 model from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/tnaduc/Documents/DeepLearning/Projects/DogCat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify we are in the project directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000): os.rename(shuf[i], DATA_HOME_DIR+'/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200): copyfile(shuf[i], DATA_HOME_DIR+'/sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare sample data for quick experiements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50): copyfile(shuf[i], DATA_HOME_DIR+'/sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute data to appropreate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data/sample/train\n",
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data/sample/valid\n",
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data/valid\n",
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data/train\n"
     ]
    }
   ],
   "source": [
    "#Divide cat/dog images into separate directories\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import numpy as np\n",
    "import json, os\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Vgg is trained using imageNet images. The authors substracted average channel values so that their input data has zero mean for each channel. In addtion, their channel order is B,G,R, whereas Python by default uses R,G,B. We need to preprocess our data to make these two changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 123.68 ]],\n",
       "\n",
       "       [[ 116.779]],\n",
       "\n",
       "       [[ 103.939]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Channel B,G, R means\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # change order to BGR \n",
    "\n",
    "vgg_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vgg16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1000)          4097000     dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define vgg16 model as a Python object\n",
    "\n",
    "def Vgg16():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224))) # Theano shape\n",
    "    \n",
    "    ###### Convolution Block 1  #########\n",
    "    # Convolution layer 1\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64,3, 3, activation='relu' )) \n",
    "    # Convilution layer 2\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64,3, 3, activation='relu' ))\n",
    "    # Maxpool 1\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "   \n",
    "    ###### Convolution Block 2  #########\n",
    "    # Convolution layer 3\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128,3, 3, activation='relu' )) \n",
    "    # Convilution layer 4\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128,3, 3, activation='relu' ))\n",
    "    # Maxpool 2\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    ###### Convolution Block 3  #########\n",
    "    # Convolution layer 5\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256,3, 3, activation='relu' )) \n",
    "    # Convilution layer 6\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256,3, 3, activation='relu' ))\n",
    "    # Convilution layer 7\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256,3, 3, activation='relu' ))\n",
    "    # Maxpool 3\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    ###### Convolution Block 4  #########\n",
    "    # Convolution layer 5\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,3, 3, activation='relu' )) \n",
    "    # Convilution layer 6\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,3, 3, activation='relu' ))\n",
    "    # Convilution layer 7\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,3, 3, activation='relu' ))\n",
    "    # Maxpool 3\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    ###### Convolution Block 5  #########\n",
    "    # Convolution layer 5\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,3, 3, activation='relu' )) \n",
    "    # Convilution layer 6\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,3, 3, activation='relu' ))\n",
    "    # Convilution layer 7\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,3, 3, activation='relu' ))\n",
    "    # Maxpool 3\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    # Flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense 1\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Dense 2\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model\n",
    "model =Vgg16()\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download the pretrained weights that vgg16 creators has trained from iamgeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.platform.ai/models/vgg16.h5\n"
     ]
    }
   ],
   "source": [
    "# ulr to download pretrained weights\n",
    "FILES_PATH = 'http://www.platform.ai/models/';\n",
    "# using Keras get_file method to download and cache the weights\n",
    "fpath = get_file('vgg16.h5', FILES_PATH+'vgg16.h5', cache_subdir='models')\n",
    "# load the weights to our previous built vgg16 model\n",
    "model.load_weights(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adapt pretrained model to our classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did previously allows us to have a model that was trained on a very large number of ImageNet images to classify 1000 object categeries. During that training process, the model has learned many important features of the world such as shapes (rounds, squares, angles, etc), colors, faces, etc. Thus, we have a very general purpose model that may contain many features that we want to learn for our particular problems at hand. \n",
    "\n",
    "*** The important idea is if we are classifying objects that are not EVEN in the 1000 ImageNet categories, there are still learned features in the pretrained model that are relevant and useful to our problem **\n",
    "\n",
    "Now, come back to our specific problem - classify dogs and cats, we know that imageNet database contains a lot of dog and cat pictures. Therefore, the pretrained model (weights) may already contained important features to distinguish dogs and cats. We will leverage the pretrained model's power and also adapt to our specific tasks- classify two categories instead of 1000 categories.\n",
    "\n",
    "So, our plan is:\n",
    "\n",
    "1. Take the pretrained model and set all the layers except the last layer to be \"untrainable\", i.e., we will not train them. \n",
    "\n",
    "2. Stick a dense layer with softmax activation which outputs 2 categories at the end.\n",
    "\n",
    "2. Pass our data into the model to train the last dense layer.\n",
    "\n",
    "**** Why we remove the last layer? because it has a softmax activation and stick another dense layer with another softmax activation is unusual (odd) since softmax outputs probabilities, it often activates the last layer not interminate layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set all the layers to untrainale.\n",
    "model.pop()\n",
    "for layer in model.layers: layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a dense layer on top of vgg16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             8194        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's see the outcome model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okie, we've got what we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training preparation\n",
    "\n",
    "We have two options to train the pretrained model:\n",
    "\n",
    "*** Option 1:*** Build a completely separate dense model.\n",
    "1. Generate predictions from pretrained model as input to our new (dense) model. \n",
    "2. Use this input to train our new model.\n",
    "\n",
    "*** Option 2: *** Build a new model with the part taken from vgg16 model and add our new dense model on top of it.\n",
    "\n",
    "1. Feed data to entire big model.\n",
    "2. Only back-prop (train) the layers we want to train.\n",
    "\n",
    "\n",
    "The option 1 has a big advantage on computational time because we essentially pre-calculate the input for the dense layers and train the dense layers is fast. But coding option 1 is a little bit more complicated. Option 2 takes a bit longer time to train but coding is pretty straightforward. As the result, I go for option 2.\n",
    "### Batches preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data\n"
     ]
    }
   ],
   "source": [
    "# Prepare path to data\n",
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to get batches\n",
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare batches for training and validation\n",
    "\n",
    "# Using helper\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "val_batches = get_batches(valid_path, gen, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#gen = image.ImageDataGenerator()\n",
    "#batches = gen.flow_from_directory(train_path, shuffle = True, target_size=(224,224), batch_size = batch_size)\n",
    "#val_batches = gen.flow_from_directory(valid_path, shuffle = True, target_size=(224,224), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complie and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile, seting hyperparameters : optimization method, learning rate, loss, validation metric\n",
    "opt = RMSprop(lr =0.1)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "# Define a helper function to call multiple times\n",
    "def fit_model(model, batches, val_batches, nb_epoch =1):\n",
    "    model.fit_generator(batches, samples_per_epoch = batch_size, nb_epoch =nb_epoch,\n",
    "                       validation_data = val_batches,nb_val_samples = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4/4 [==============================] - 65s - loss: 0.6455 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 46s - loss: 12.0886 - acc: 0.2500 - val_loss: 4.0295 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "fit_model(model,batches,val_batches,nb_epoch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our trained model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/tnaduc/Documents/DeepLearning/Projects/DogCat/data'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tnaduc/Documents/DeepLearning/Projects/DogCat\n",
      "mkdir: cannot create directory ‘Models’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# Back to project dir\n",
    "%cd $current_dir\n",
    "# Create a directory to save model\n",
    "%mkdir Models\n",
    "\n",
    "model_path = current_dir + '/Models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_weights(model_path + 'model_tune_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaludate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to get data\n",
    "def get_data(path, target_size=(224,224)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in range(batches.nb_sample)])\n",
    "\n",
    "# Onehot encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def onehot(x):\n",
    "    return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get validation data\n",
    "val_data = get_data(valid_path)\n",
    "# Get validation labels\n",
    "val_classes =val_batches.classes\n",
    "val_labels = onehot(val_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 289s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.3484949159622186, 0.41999999999999998]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reporting loss and accuracy\n",
    "model.evaluate(val_data,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 349s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "preds = model.predict_classes(val_data, batch_size =batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix is a good tool to see performance of binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cfmatrix = confusion_matrix(val_classes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 29]\n",
      " [ 0 21]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAGbCAYAAACveWuNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1c436da50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper function to plot confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    (This function is copied from the scikit docs.)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(cfmatrix, val_batches.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so good. We can, instead of training only the last layer, train all the dense layers. Why shouldn't we touch the convolutional layers? Because, in my opinion, convolutional layers store most of the information that the model learned from ImageNet database such as shapes, orientations, faces,etc. By touching these layers, we may very well detroy valuable features.\n",
    "\n",
    "# Train all the dense layers in Vgg16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plan is to train all the dense layers. We can still train the convolutional layers if we want and we can even design our all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "# Get the first layers\n",
    "first_layer = [index for index, layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "# Set all the layers from the first dense layers to be trainable\n",
    "for layer in layers[first_layer:]: layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okie, all the dense layers are now trainable. Note that we didn't modify the architechure of the model at all, we just allow it to train new layers so we do not need to recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             8194        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 119,554,050\n",
      "Non-trainable params: 14,714,688\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now have nearly 15 millions parameters, training will take much longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4/4 [==============================] - 50s - loss: 8.0590 - acc: 0.5000 - val_loss: 12.0886 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "K.set_value(opt.lr,0.01)\n",
    "fit_model(model, batches,val_batches, 1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
